{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqdd1k70Dk2dBP4aYj3aWz","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":"<a href=\"https://colab.research.google.com/github/Ditsuhi/Nitrogen_Dioxide_Prediction/blob/main/Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"},{"cell_type":"code","source":"# import all required libraries\n\nimport zipfile\nfrom glob import glob\nimport re\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom scipy.interpolate import NearestNDInterpolator\nfrom keras.models import Sequential\nfrom keras.layers import ConvLSTM2D, BatchNormalization, Bidirectional, Conv2D\nfrom time import time\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"id":"tdMCCoKA6PpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jREIAZxGuDsH"},"outputs":[],"source":"# To calculate nearest neighbor interpolation for meteorological data\n\ndef CalcNNvalue(array_interpolate):\n  \n  array_float = array_interpolate.astype(float)\n  knowncell_position= np.argwhere(array_float!=0)  \n  knowncell_value = array_float[array_float!=0] \n  unknowncell_position = np.argwhere(array_float==0)\n  myInterpolator = NearestNDInterpolator(knowncell_position, knowncell_value) \n  unknown_values = myInterpolator(unknowncell_position)\n  array_float[array_float == 0 ] = unknown_values\n  return array_float.tolist()\n\n\ndef calc_NN_fullData(full_data):\n  NN_list =[]\n  for item in full_data:    \n    try: \n      NN_list.append(CalcNNvalue(item))\n    except IndexError:\n      NN_list.append(item.tolist())  \n  return NN_list\n\n\ndef calculate_NN_fullData_allAttributes (df_all):\n  df_all_NN_list = []\n  # The number in the range is the number of meteorological features \n  # to be interpolated using nearest neighbor interpolation.  \n  for attr_numb in range(1): \n    certain_attr = df_all[:, :, attr_numb]    \n    certain_attr_reshaped= certain_attr.reshape(certain_attr.shape[0], 20, 17)\n    certain_attr_reshaped_NN = calc_NN_fullData(certain_attr_reshaped) \n    certain_attr_reshaped_NN_original_shape = np.reshape(certain_attr_reshaped_NN, (certain_attr.shape[0], 340))\n    df_all_NN_list.append(certain_attr_reshaped_NN_original_shape.tolist())   \n  df_all_NN_array = np.dstack((item)for item in df_all_NN_list)  \n  return df_all_NN_array"},{"cell_type":"code","source":"#unzip data giving the path of certain dataset\n\npath = '/data/AirMetTraffic_2019_2020_firstSixMonths.zip'\nwith zipfile.ZipFile(path, 'r') as zip_ref:\n    zip_ref.extractall('/data/')\n\nairMetTraf = glob(\"/data/*.csv\")\n\n","metadata":{"id":"N06QOh1fugjg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sort dataset in chronological order\n\n\ndef sortingFiles(eachFile):\n    return int(eachFile) if eachFile.isdigit() else eachFile\ndef natural_keys(eachFile):\n    return [sortingFiles(c) for c in re.split('(\\d+)',eachFile)]\n\nsorted_airMetTraf= sorted(airMetTraf, key = natural_keys)\nsorted_airMetTraf_2019 = sorted_airMetTraf[:4344]\nsorted_airMetTraf_2020= sorted_airMetTraf[4344:]","metadata":{"id":"r7RyhkxauoKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These are the feyures from the matrices: FID\t NO2\t UV\t windSpeed\t windDir\t Temp\t Humidity\t Pressure\t SolarRad\t Prec\t intensidad\t ocupacion\t carga\t vmed\n\ndf_2019 = [pd.read_csv(f, usecols=[' NO2', ' UV',  ' windSpeed', ' windDir', ' Temp', ' Humidity', ' Pressure', ' SolarRad', ' Prec', ' intensidad',\t' ocupacion',\t' carga',\t ' vmed']).values for f in sorted_airMetTraf_2019]\n#df_2020 = [pd.read_csv(f, usecols=[' NO2', ' UV',  ' windSpeed', ' windDir', ' Temp', ' Humidity', ' Pressure', ' SolarRad', ' Prec', ' intensidad',\t' ocupacion',\t' carga',\t ' vmed']).values for f in sorted_airMetTraf_2020]","metadata":{"id":"bsXY4bOdu77k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all_2019  = np.asarray(df_2019)\n#df_all_2020  = np.asarray(df_2020)","metadata":{"id":"ob6shDDXwKIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# This step is for outlier handling (Temperature:res; Humidity:reshum;\n# and Average Speed:speed)\n\ndef tempOut (df_all):\n  return np.where(df_all[:, :, 4] < -3)\n\ndef humOut (df_all):\n  return np.where(df_all[:, :, 5] < 0)\n\ndef speedOut (df_all):\n  return np.where(df_all[:, :, 12] < 0)\n\nres = tempOut (df_all_2019)\nreshum = humOut (df_all_2019)\nspeed = speedOut (df_all_2019)\n\n\n# all values for a temperature data below -3 are converted to an average\n# before and after the values.\n\nfor i in range(len(res[0])):\n  if df_all[:, :, 4][res[0][i]][res[1][i]-1] > -3 and df_all[:, :, 4][res[0][i]][res[1][i]+1] > -3:\n    df_all[:, :, 4][res[0][i]][res[1][i]] = (df_all[:, :, 4][res[0][i]][res[1][i]-1]+df_all[:, :, 4][res[0][i]][res[1][i]+1])/2\n\n\n# all values for a humidity data below 0 are converted to an average\n# before and after the values.\n\nfor i in range(len(reshum[0])):\n  if df_all[:, :, 5][reshum[0][i]][reshum[1][i]-1] >= 0 and df_all[:, :, 5][reshum[0][i]][reshum[1][i]+1] >= 0:\n    df_all[:, :, 5][reshum[0][i]][reshum[1][i]] = (df_all[:, :, 5][reshum[0][i]][reshum[1][i]-1]+df_all[:, :, 5][reshum[0][i]][reshum[1][i]+1])/2\n\n\n# all values for a speed data below 0 are converted to 0.\n\nfor i in range(len(speed[0])):\n  df_all[:, :, 12][speed[0][i]][speed[1][i]] = 0\n\n\n# deleting precipitation, because most values are 0\n\ndf_all_non_prec = np.delete(df_all, 8, 2)\nair= df_all_non_prec[:, :, 0].reshape(-1, 340, 1)\ntraf =  df_all_non_prec[:, :, 8:12].reshape(-1, 340, 4)\nNN_dataframe = calculate_NN_fullData_allAttributes (df_all_non_prec[:, :, 1:8])\ndf_air_NN_Met = np.concatenate((air, idw_dataframe, traf), axis=2)\nnot_nun = np.nan_to_num(df_air_NN_Met)\nround_data = np.round(not_nun, 1)","metadata":{"id":"pg8vhfF9vhSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert wind direction to categorical data, and then apply One Hot Encoder\n\ndf_categ = pd.DataFrame(round_data.reshape(-1, 12), columns = ['NO2', 'UV',  'windSpeed', 'windDir', 'Temp', 'Humidity', 'Pressure', 'SolarRad',  'intensidad',\t'ocupacion',\t'carga',\t 'vmed'])\n\ndf_categ['windDir_Categ'] = \"\"\n\nfor item in range(0, len(df_categ)):\n  if (df_categ['windDir'][item] >=0 and  df_categ['windDir'][item] <22.5) or df_categ['windDir'][item] >337.5:\n    df_categ['windDir_Categ'][item] = 'north'        \n  elif df_categ['windDir'][item] >=22.5 and  df_categ['windDir'][item] < 67.5:\n    df_categ['windDir_Categ'][item] = 'northeast' \n  elif df_categ['windDir'][item] >=67.5 and  df_categ['windDir'][item] < 112.5:\n    df_categ['windDir_Categ'][item] = 'east' \n  elif df_categ['windDir'][item] >=112.5 and  df_categ['windDir'][item] < 157.5:\n    df_categ['windDir_Categ'][item] = 'southeast' \n  elif df_categ['windDir'][item] >=157.5 and  df_categ['windDir'][item] < 202.5:\n    df_categ['windDir_Categ'][item] = 'south' \n  elif df_categ['windDir'][item] >=202.5 and  df_categ['windDir'][item] < 247.5:\n    df_categ['windDir_Categ'][item] = 'southwest' \n  elif df_categ['windDir'][item] >=247.5 and  df_categ['windDir'][item] < 292.5:\n    df_categ['windDir_Categ'][item] = 'west' \n  else: \n    df_categ['windDir_Categ'][item] = 'northwest' \n","metadata":{"id":"OzX4KiJux9fP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder=OneHotEncoder(sparse=False)\ndf_categ_encoded = pd.DataFrame(encoder.fit_transform(df_categ[['windDir_Categ']]))\ndf_categ_encoded.columns = encoder.get_feature_names(['windDir_Categ'])\ndf_categ.drop(['windDir_Categ'] ,axis=1, inplace=True)\nOH_X_train= pd.concat([df_categ, df_categ_encoded ], axis=1)\n\n#create final dataset for further analyses by deleting windir, as it is aready converted to caregorical data; deleting UV as it is not available for June 2019 and for whole period of 2020;  \n#deleting carga(Traffic load-according to the definition is the combination of intensity, occupancy time and capacity of the road),\n# and vmed(average traffic speed - because it is available only for M30 road which is 15.8% of the case study)\n\nfinal_dataframe = OH_X_train.drop(['windDir', 'UV', 'carga', 'vmed'], axis = 1)","metadata":{"id":"DifHAcVQ6Ont"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"xVi_sxfhynlP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SE6_cGufySr9"},"execution_count":null,"outputs":[]}]}